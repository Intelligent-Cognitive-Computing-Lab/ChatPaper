#!/usr/bin/env python3
"""
ChatPaper - VLAæ¨¡å‹èµ„æºå—é™ç ”ç©¶ç»¼è¿°å·¥å…·
ä¸»å…¥å£ç¨‹åºï¼Œé›†æˆè®ºæ–‡åˆ†æã€æŠ¥å‘Šç”Ÿæˆå’ŒLLMæ™ºèƒ½ç»¼è¿°åŠŸèƒ½
"""

import os
import sys
import argparse
from datetime import datetime

# æ·»åŠ srcç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'src'))

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(
        description='ChatPaper - VLAæ¨¡å‹èµ„æºå—é™ç ”ç©¶ç»¼è¿°å·¥å…·',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¤ºä¾‹:
  
  1. æ‰¹é‡åˆ†æPDFè®ºæ–‡:
     python main.py analyze --pdf_path papers/ --parallel --max_workers 3
  
  2. ç”Ÿæˆç»Ÿè®¡åˆ†ææŠ¥å‘Š:
     python main.py report --csv_path results/export/vla_all_250729.csv
  
  3. ä½¿ç”¨LLMç”Ÿæˆæ™ºèƒ½ç»¼è¿°:
     python main.py survey --csv_path results/export/vla_all_250729.csv --generate_chapters
  
  4. å®Œæ•´æµç¨‹ï¼ˆåˆ†æ+æŠ¥å‘Š+ç»¼è¿°ï¼‰:
     python main.py full --pdf_path papers/ --parallel
        """
    )
    
    subparsers = parser.add_subparsers(dest='command', help='å¯ç”¨å‘½ä»¤')
    
    # 1. è®ºæ–‡åˆ†æå‘½ä»¤
    analyze_parser = subparsers.add_parser('analyze', help='æ‰¹é‡åˆ†æPDFè®ºæ–‡')
    analyze_parser.add_argument('--pdf_path', required=True, help='PDFæ–‡ä»¶æˆ–æ–‡ä»¶å¤¹è·¯å¾„')
    analyze_parser.add_argument('--key_word', default='vision language action', help='ç ”ç©¶é¢†åŸŸå…³é”®è¯')
    analyze_parser.add_argument('--parallel', action='store_true', help='å¯ç”¨å¤šçº¿ç¨‹å¹¶è¡Œå¤„ç†')
    analyze_parser.add_argument('--max_workers', type=int, default=3, help='å¹¶å‘çº¿ç¨‹æ•°')
    analyze_parser.add_argument('--max_tokens', type=int, default=60000, help='æœ€å¤§tokenæ•°')
    analyze_parser.add_argument('--language', default='zh', help='è¾“å‡ºè¯­è¨€')
    analyze_parser.add_argument('--resume', action='store_true', help='æ–­ç‚¹ç»­ä¼ ')
    
    # 2. æŠ¥å‘Šç”Ÿæˆå‘½ä»¤
    report_parser = subparsers.add_parser('report', help='ç”Ÿæˆç»Ÿè®¡åˆ†ææŠ¥å‘Š')
    report_parser.add_argument('--csv_path', required=True, help='CSVæ•°æ®æ–‡ä»¶è·¯å¾„')
    report_parser.add_argument('--output_dir', default='results/analysis_results', help='è¾“å‡ºç›®å½•')
    
    # 3. æ™ºèƒ½ç»¼è¿°å‘½ä»¤
    survey_parser = subparsers.add_parser('survey', help='ä½¿ç”¨LLMç”Ÿæˆæ™ºèƒ½ç»¼è¿°')
    survey_parser.add_argument('--csv_path', required=True, help='CSVæ•°æ®æ–‡ä»¶è·¯å¾„')
    survey_parser.add_argument('--analysis_dir', default='results/analysis_results', help='åˆ†æç»“æœç›®å½•')
    survey_parser.add_argument('--generate_chapters', action='store_true', help='ç”Ÿæˆè¯¦ç»†ç« èŠ‚å†…å®¹')
    survey_parser.add_argument('--output_dir', default='results/intelligent_survey_results', help='è¾“å‡ºç›®å½•')
    
    # 4. å®Œæ•´æµç¨‹å‘½ä»¤
    full_parser = subparsers.add_parser('full', help='å®Œæ•´æµç¨‹ï¼ˆåˆ†æ+æŠ¥å‘Š+ç»¼è¿°ï¼‰')
    full_parser.add_argument('--pdf_path', required=True, help='PDFæ–‡ä»¶æˆ–æ–‡ä»¶å¤¹è·¯å¾„')
    full_parser.add_argument('--parallel', action='store_true', help='å¯ç”¨å¤šçº¿ç¨‹å¹¶è¡Œå¤„ç†')
    full_parser.add_argument('--max_workers', type=int, default=3, help='å¹¶å‘çº¿ç¨‹æ•°')
    full_parser.add_argument('--generate_chapters', action='store_true', help='ç”Ÿæˆè¯¦ç»†ç« èŠ‚å†…å®¹')
    
    args = parser.parse_args()
    
    if not args.command:
        parser.print_help()
        return
    
    print("ğŸš€ ChatPaper - VLAæ¨¡å‹èµ„æºå—é™ç ”ç©¶ç»¼è¿°å·¥å…·")
    print("=" * 60)
    print(f"â° å¯åŠ¨æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"ğŸ”§ æ‰§è¡Œå‘½ä»¤: {args.command}")
    print()
    
    try:
        if args.command == 'analyze':
            run_analyze(args)
        elif args.command == 'report':
            run_report(args)
        elif args.command == 'survey':
            run_survey(args)
        elif args.command == 'full':
            run_full_pipeline(args)
            
    except KeyboardInterrupt:
        print("\nâš ï¸  ç”¨æˆ·ä¸­æ–­æ‰§è¡Œ")
    except Exception as e:
        print(f"\nâŒ æ‰§è¡Œå¤±è´¥: {str(e)}")
        return 1
    
    print(f"\nâœ… ä»»åŠ¡å®Œæˆ! ç»“æœä¿å­˜åœ¨ results/ ç›®å½•ä¸‹")
    return 0

def run_analyze(args):
    """æ‰§è¡Œè®ºæ–‡åˆ†æ"""
    from chat_paper_simple import main as analyze_main
    
    print("ğŸ“š å¼€å§‹æ‰¹é‡åˆ†æPDFè®ºæ–‡...")
    
    # æ„å»ºåˆ†æå‚æ•°
    analyze_args = [
        '--pdf_path', args.pdf_path,
        '--key_word', args.key_word,
        '--language', args.language,
        '--max_tokens', str(args.max_tokens)
    ]
    
    if args.parallel:
        analyze_args.extend(['--parallel', '--max_workers', str(args.max_workers)])
    
    if args.resume:
        analyze_args.append('--resume')
    
    # ä¸´æ—¶ä¿®æ”¹sys.argvæ¥ä¼ é€’å‚æ•°
    original_argv = sys.argv
    sys.argv = ['chat_paper_simple.py'] + analyze_args
    
    try:
        analyze_main()
    finally:
        sys.argv = original_argv
    
    print("âœ… è®ºæ–‡åˆ†æå®Œæˆ")

def run_report(args):
    """æ‰§è¡ŒæŠ¥å‘Šç”Ÿæˆ"""
    from vla_survey_analyzer import VLASurveyAnalyzer
    
    print("ğŸ“Š å¼€å§‹ç”Ÿæˆç»Ÿè®¡åˆ†ææŠ¥å‘Š...")
    
    if not os.path.exists(args.csv_path):
        raise FileNotFoundError(f"CSVæ–‡ä»¶ä¸å­˜åœ¨: {args.csv_path}")
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(args.output_dir, exist_ok=True)
    
    # ç”ŸæˆæŠ¥å‘Š
    analyzer = VLASurveyAnalyzer(args.csv_path)
    analyzer.generate_comprehensive_report(args.output_dir)
    
    print("âœ… ç»Ÿè®¡åˆ†ææŠ¥å‘Šç”Ÿæˆå®Œæˆ")

def run_survey(args):
    """æ‰§è¡Œæ™ºèƒ½ç»¼è¿°ç”Ÿæˆ"""
    from vla_intelligent_survey_generator import VLAIntelligentSurveyGenerator
    
    print("ğŸ¤– å¼€å§‹ä½¿ç”¨LLMç”Ÿæˆæ™ºèƒ½ç»¼è¿°...")
    
    if not os.path.exists(args.csv_path):
        raise FileNotFoundError(f"CSVæ–‡ä»¶ä¸å­˜åœ¨: {args.csv_path}")
    
    if not os.path.exists(args.analysis_dir):
        raise FileNotFoundError(f"åˆ†æç»“æœç›®å½•ä¸å­˜åœ¨: {args.analysis_dir}")
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(args.output_dir, exist_ok=True)
    
    # åˆå§‹åŒ–ç»¼è¿°ç”Ÿæˆå™¨
    generator = VLAIntelligentSurveyGenerator(
        args.csv_path, 
        args.analysis_dir,
        config_path='config/apikey.ini'
    )
    
    # ç”Ÿæˆç»¼è¿°æ¡†æ¶
    print("ğŸ“‹ ç”Ÿæˆç»¼è¿°æ¡†æ¶...")
    framework = generator.generate_survey_framework()
    
    # åˆ†ç±»è®ºæ–‡
    print("ğŸ“š åˆ†ç±»è®ºæ–‡...")
    classification = generator.classify_papers_by_themes(framework)
    
    # ä¿å­˜åŸºç¡€ç»“æœ
    import json
    framework_path = os.path.join(args.output_dir, 'survey_framework.json')
    with open(framework_path, 'w', encoding='utf-8') as f:
        json.dump(framework, f, ensure_ascii=False, indent=2)
    
    classification_path = os.path.join(args.output_dir, 'paper_classification.json')
    with open(classification_path, 'w', encoding='utf-8') as f:
        json.dump(classification, f, ensure_ascii=False, indent=2)
    
    print(f"âœ… æ¡†æ¶å’Œåˆ†ç±»å·²ä¿å­˜")
    
    # å¦‚æœéœ€è¦ç”Ÿæˆè¯¦ç»†ç« èŠ‚
    if args.generate_chapters:
        print("ğŸ“ ç”Ÿæˆè¯¦ç»†ç« èŠ‚å†…å®¹...")
        generate_detailed_chapters(generator, framework, classification, args.output_dir)
    
    print("âœ… æ™ºèƒ½ç»¼è¿°ç”Ÿæˆå®Œæˆ")

def generate_detailed_chapters(generator, framework, classification, output_dir):
    """ç”Ÿæˆè¯¦ç»†ç« èŠ‚å†…å®¹"""
    
    chapters_dir = os.path.join(output_dir, 'chapters')
    os.makedirs(chapters_dir, exist_ok=True)
    
    # é€‰æ‹©è¦ç”Ÿæˆçš„æ ¸å¿ƒç« èŠ‚
    target_sections = [
        "Introduction",
        "VLA Architecture Taxonomy", 
        "Resource Bottleneck Analysis",
        "Solution Strategies and Innovations"
    ]
    
    generated_chapters = []
    
    for section in framework.get('sections', []):
        section_name = section['name']
        
        if section_name not in target_sections:
            continue
            
        subsections = section.get('subsections', [])
        max_pages = section.get('pages', 3)
        
        print(f"  ğŸ“ ç”Ÿæˆç« èŠ‚: {section_name}")
        
        # è·å–ç›¸å…³è®ºæ–‡
        related_papers = []
        for category, papers in classification.items():
            if isinstance(papers, list):
                related_papers.extend(papers[:5])
                if len(related_papers) >= 15:
                    break
        
        # ç”Ÿæˆç« èŠ‚å†…å®¹
        content = generator.generate_section_content(
            section_name, subsections, related_papers, max_pages
        )
        
        # ä¿å­˜ç« èŠ‚
        safe_name = section_name.replace(' ', '_').replace('/', '_').lower()
        chapter_file = os.path.join(chapters_dir, f"{safe_name}.md")
        
        with open(chapter_file, 'w', encoding='utf-8') as f:
            f.write(f"# {section_name}\n\n")
            f.write(content)
        
        generated_chapters.append({
            'name': section_name,
            'file': chapter_file,
            'length': len(content)
        })
        
        print(f"     âœ… å®Œæˆ ({len(content)} å­—ç¬¦)")
    
    # ç”Ÿæˆç›®å½•
    generate_chapters_index(framework, generated_chapters, chapters_dir)
    
    print(f"  ğŸ“‘ å·²ç”Ÿæˆ {len(generated_chapters)} ä¸ªç« èŠ‚")

def generate_chapters_index(framework, generated_chapters, chapters_dir):
    """ç”Ÿæˆç« èŠ‚ç›®å½•"""
    
    index_content = f"""# VLAæ¨¡å‹èµ„æºå—é™ç ”ç©¶ç»¼è¿°

*ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S')}*

## ç›®å½•

"""
    
    chapter_files = {ch['name']: os.path.basename(ch['file']) for ch in generated_chapters}
    
    for i, section in enumerate(framework.get('sections', [])):
        section_name = section['name']
        pages = section.get('pages', 3)
        
        if section_name in chapter_files:
            filename = chapter_files[section_name]
            index_content += f"{i+1}. [{section_name}](./{filename}) *({pages}é¡µ)* âœ…\n"
        else:
            index_content += f"{i+1}. {section_name} *({pages}é¡µ)* â³\n"
        
        for j, subsection in enumerate(section.get('subsections', [])):
            index_content += f"   {i+1}.{j+1} {subsection}\n"
        
        index_content += "\n"
    
    index_content += f"""
## ç”Ÿæˆç»Ÿè®¡

- **å·²ç”Ÿæˆç« èŠ‚**: {len(generated_chapters)}/{len(framework.get('sections', []))}
- **æ€»å­—ç¬¦æ•°**: {sum(ch['length'] for ch in generated_chapters):,}

---
*æœ¬ç»¼è¿°ç”±ChatPaperæ™ºèƒ½ç”Ÿæˆ*
"""
    
    index_file = os.path.join(chapters_dir, "README.md")
    with open(index_file, 'w', encoding='utf-8') as f:
        f.write(index_content)

def run_full_pipeline(args):
    """è¿è¡Œå®Œæ•´æµç¨‹"""
    print("ğŸ”„ å¼€å§‹æ‰§è¡Œå®Œæ•´æµç¨‹...")
    
    # 1. åˆ†æè®ºæ–‡
    print("\n" + "="*50)
    print("ç¬¬1æ­¥: æ‰¹é‡åˆ†æPDFè®ºæ–‡")
    print("="*50)
    
    analyze_args_obj = argparse.Namespace(
        pdf_path=args.pdf_path,
        key_word='vision language action',
        parallel=args.parallel,
        max_workers=args.max_workers,
        max_tokens=60000,
        language='zh',
        resume=False
    )
    run_analyze(analyze_args_obj)
    
    # æŸ¥æ‰¾ç”Ÿæˆçš„CSVæ–‡ä»¶
    export_dir = 'results/export'
    if os.path.exists(export_dir):
        csv_files = [f for f in os.listdir(export_dir) if f.endswith('.csv') and 'merged' in f]
        if csv_files:
            # ä½¿ç”¨æœ€æ–°çš„CSVæ–‡ä»¶
            csv_files.sort(reverse=True)
            csv_path = os.path.join(export_dir, csv_files[0])
        else:
            raise FileNotFoundError("æœªæ‰¾åˆ°ç”Ÿæˆçš„CSVæ–‡ä»¶")
    else:
        raise FileNotFoundError("exportç›®å½•ä¸å­˜åœ¨")
    
    # 2. ç”ŸæˆæŠ¥å‘Š
    print("\n" + "="*50)
    print("ç¬¬2æ­¥: ç”Ÿæˆç»Ÿè®¡åˆ†ææŠ¥å‘Š")
    print("="*50)
    
    report_args_obj = argparse.Namespace(
        csv_path=csv_path,
        output_dir='results/analysis_results'
    )
    run_report(report_args_obj)
    
    # 3. ç”Ÿæˆæ™ºèƒ½ç»¼è¿°
    print("\n" + "="*50)
    print("ç¬¬3æ­¥: ç”Ÿæˆæ™ºèƒ½ç»¼è¿°")
    print("="*50)
    
    survey_args_obj = argparse.Namespace(
        csv_path=csv_path,
        analysis_dir='results/analysis_results',
        generate_chapters=args.generate_chapters,
        output_dir='results/intelligent_survey_results'
    )
    run_survey(survey_args_obj)
    
    print("\nğŸ‰ å®Œæ•´æµç¨‹æ‰§è¡Œå®Œæˆ!")
    print(f"ğŸ“ æ‰€æœ‰ç»“æœå·²ä¿å­˜åœ¨ results/ ç›®å½•ä¸‹")

if __name__ == "__main__":
    sys.exit(main())
